[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "",
    "text": "Screenshot of homepage"
  },
  {
    "objectID": "index.html#quickstart",
    "href": "index.html#quickstart",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Quickstart",
    "text": "Quickstart\nThis quickstart guide provides a high-level overview. See the full documentation for comprehensive information on features, installation, architecture, conventions, code style, and customization, deployment to cloud platforms, and contributing."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Features",
    "text": "Features\nThis template combines three of the most lightweight and performant open-source web development frameworks into a customizable webapp template with:\n\nPure Python backend\nMinimal-Javascript frontend\nPowerful, easy-to-manage database\n\nThe template also includes full-featured secure auth with:\n\nToken-based authentication\nPassword recovery flow\nRole-based access control system"
  },
  {
    "objectID": "index.html#design-philosophy",
    "href": "index.html#design-philosophy",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Design Philosophy",
    "text": "Design Philosophy\nThe design philosophy of the template is to prefer low-level, best-in-class open-source frameworks that offer flexibility, scalability, and performance without vendor-lock-in. You’ll find the template amazingly easy not only to understand and customize, but also to deploy to any major cloud hosting platform."
  },
  {
    "objectID": "index.html#tech-stack",
    "href": "index.html#tech-stack",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Tech Stack",
    "text": "Tech Stack\nCore frameworks:\n\nFastAPI: scalable, high-performance, type-annotated Python web backend framework\nPostgreSQL: the world’s most advanced open-source database engine\nJinja2: frontend HTML templating engine\nSQLModel: easy-to-use Python ORM\n\nAdditional technologies:\n\nuv: Python dependency manager\nPytest: testing framework\nDocker: development containerization\nGithub Actions: CI/CD pipeline\nQuarto: simple documentation website renderer\nMyPy: static type checker for Python\nBootstrap: HTML/CSS styler\nResend: zero- or low-cost email service used for password recovery"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Installation",
    "text": "Installation\nFor comprehensive installation instructions, see the installation page.\n\nuv\nMacOS and Linux:\nwget -qO- https://astral.sh/uv/install.sh | sh\nWindows:\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\nSee the uv installation docs for more information.\n\n\nPython\nInstall Python 3.12 or higher from either the official downloads page or using uv:\n# Installs the latest version\nuv python install\n\n\nDocker and Docker Compose\nInstall Docker Desktop and Coker Compose for your operating system by following the instructions in the documentation.\n\n\nPostgreSQL headers\nFor Ubuntu/Debian:\nsudo apt update && sudo apt install -y python3-dev libpq-dev\nFor macOS:\nbrew install postgresql\nFor Windows:\n\nNo installation required\n\n\n\nPython dependencies\nFrom the root directory, run:\nuv venv\nuv sync\nThis will create an in-project virtual environment and install all dependencies.\n\n\nSet environment variables\nCopy .env.example to .env with cp .env.example .env.\nGenerate a 256 bit secret key with openssl rand -base64 32 and paste it into the .env file.\nSet your desired database name, username, and password in the .env file.\nTo use password recovery, register a Resend account, verify a domain, get an API key, and paste the API key into the .env file.\n\n\nStart development database\nTo start the development database, run the following command in your terminal from the root directory:\ndocker compose up -d\n\n\nRun the development server\nMake sure the development database is running and tables and default permissions/roles are created first.\nuvicorn main:app --host 0.0.0.0 --port 8000 --reload\nNavigate to http://localhost:8000/\n\n\nLint types with mypy\nmypy ."
  },
  {
    "objectID": "index.html#developing-with-llms",
    "href": "index.html#developing-with-llms",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Developing with LLMs",
    "text": "Developing with LLMs\nIn line with the llms.txt standard, we have provided a Markdown-formatted prompt—designed to help LLM agents understand how to work with this template—as a text file: llms.txt.\nOne use case for this file, if using the Cursor IDE, is to rename it to .cursorrules and place it in your project directory (see the Cursor docs on this for more information). Alternatively, you could use it as a custom system prompt in the web interface for ChatGPT, Claude, or the LLM of your choice.\nWe have also exposed the full Markdown-formatted project documentation as a single text file for easy downloading and embedding for RAG workflows."
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "Contributing",
    "text": "Contributing\nYour contributions are welcome! See the issues page for ideas. Fork the repository, create a new branch, make your changes, and submit a pull request."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "FastAPI, Jinja2, PostgreSQL Webapp Template",
    "section": "License",
    "text": "License\nThis project is created and maintained by Promptly Technologies, LLC and licensed under the MIT License. See the LICENSE file for more details."
  },
  {
    "objectID": "docs/authentication.html",
    "href": "docs/authentication.html",
    "title": "Authentication",
    "section": "",
    "text": "This template implements a comprehensive authentication system with security best practices:\n\nToken Security:\n\nJWT-based with separate access/refresh tokens\nStrict expiry times (30 min access, 30 day refresh)\nToken type validation\nHTTP-only cookies\nSecure flag enabled\nSameSite=strict restriction\n\nPassword Security:\n\nStrong password requirements enforced\nBcrypt hashing with random salt\nPassword reset tokens are single-use\nReset tokens have expiration\n\nCookie Security:\n\nHTTP-only prevents JavaScript access\nSecure flag ensures HTTPS only\nStrict SameSite prevents CSRF\n\nError Handling:\n\nValidation errors properly handled\nSecurity-related errors don’t leak information\nComprehensive error logging\n\n\nThe diagrams below show the main authentication flows."
  },
  {
    "objectID": "docs/authentication.html#security-features",
    "href": "docs/authentication.html#security-features",
    "title": "Authentication",
    "section": "",
    "text": "This template implements a comprehensive authentication system with security best practices:\n\nToken Security:\n\nJWT-based with separate access/refresh tokens\nStrict expiry times (30 min access, 30 day refresh)\nToken type validation\nHTTP-only cookies\nSecure flag enabled\nSameSite=strict restriction\n\nPassword Security:\n\nStrong password requirements enforced\nBcrypt hashing with random salt\nPassword reset tokens are single-use\nReset tokens have expiration\n\nCookie Security:\n\nHTTP-only prevents JavaScript access\nSecure flag ensures HTTPS only\nStrict SameSite prevents CSRF\n\nError Handling:\n\nValidation errors properly handled\nSecurity-related errors don’t leak information\nComprehensive error logging\n\n\nThe diagrams below show the main authentication flows."
  },
  {
    "objectID": "docs/authentication.html#registration-and-login-flow",
    "href": "docs/authentication.html#registration-and-login-flow",
    "title": "Authentication",
    "section": "Registration and login flow",
    "text": "Registration and login flow\n\n\n\nRegistration and login flow"
  },
  {
    "objectID": "docs/authentication.html#password-reset-flow",
    "href": "docs/authentication.html#password-reset-flow",
    "title": "Authentication",
    "section": "Password reset flow",
    "text": "Password reset flow\n\n\n\nPassword reset flow"
  },
  {
    "objectID": "docs/architecture.html",
    "href": "docs/architecture.html",
    "title": "Architecture",
    "section": "",
    "text": "This application uses a Post-Redirect-Get (PRG) pattern. The user submits a form, which sends a POST request to a FastAPI endpoint on the server. The database is updated, and the user is redirected to a GET endpoint, which fetches the updated data and re-renders the Jinja2 page template with the new data.\n\n\n\nData flow diagram\n\n\nThe advantage of the PRG pattern is that it is very straightforward to implement and keeps most of the rendering logic on the server side. The disadvantage is that it requires an extra round trip to the database to fetch the updated data, and re-rendering the entire page template may be less efficient than a partial page update on the client side."
  },
  {
    "objectID": "docs/architecture.html#data-flow",
    "href": "docs/architecture.html#data-flow",
    "title": "Architecture",
    "section": "",
    "text": "This application uses a Post-Redirect-Get (PRG) pattern. The user submits a form, which sends a POST request to a FastAPI endpoint on the server. The database is updated, and the user is redirected to a GET endpoint, which fetches the updated data and re-renders the Jinja2 page template with the new data.\n\n\n\nData flow diagram\n\n\nThe advantage of the PRG pattern is that it is very straightforward to implement and keeps most of the rendering logic on the server side. The disadvantage is that it requires an extra round trip to the database to fetch the updated data, and re-rendering the entire page template may be less efficient than a partial page update on the client side."
  },
  {
    "objectID": "docs/architecture.html#form-validation-flow",
    "href": "docs/architecture.html#form-validation-flow",
    "title": "Architecture",
    "section": "Form validation flow",
    "text": "Form validation flow\nWe’ve experimented with several approaches to validating form inputs in the FastAPI endpoints.\n\nObjectives\nIdeally, on an invalid input, we would redirect the user back to the form, preserving their inputs and displaying an error message about which input was invalid.\nThis would keep the error handling consistent with the PRG pattern described in the Architecture section of this documentation.\nTo keep the code DRY, we’d also like to handle such validation with Pydantic dependencies, Python exceptions, and exception-handling middleware as much as possible.\n\n\nObstacles\nOne challenge is that if we redirect back to the page with the form, the page is re-rendered with empty form fields.\nThis can be overcome by passing the inputs from the request as context variables to the template.\nBut that’s a bit clunky, because then we have to support form-specific context variables in every form page and corresponding GET endpoint.\nAlso, we have to:\n\naccess the request object (which is not by default available to our middleware), and\nextract the form inputs (at least one of which is invalid in this error case), and\npass the form inputs to the template (which is a bit challenging to do in a DRY way since there are different sets of form inputs for different forms).\n\nSolving these challenges is possible, but gets high-complexity pretty quickly.\n\n\nApproaches\nThe best solution, I think, is to use really robust client-side form validation to prevent invalid inputs from being sent to the server in the first place. That makes it less important what we do on the server side, although we still need to handle the server-side error case as a backup in the event that something slips past our validation on the client side.\nHere are some patterns we’ve considered for server-side error handling:\n\n\n\n\n\nApproach\n\n\nReturns to same page\n\n\nPreserves form inputs\n\n\nFollows PRG pattern\n\n\nComplexity\n\n\n\n\n\n\nValidate with Pydantic dependency, catch and redirect from middleware (with exception message as context) to an error page with “go back” button\n\n\nNo\n\n\nYes\n\n\nYes\n\n\nLow\n\n\n\n\nValidate in FastAPI endpoint function body, redirect to origin page with error message query param\n\n\nYes\n\n\nNo\n\n\nYes\n\n\nMedium\n\n\n\n\nValidate in FastAPI endpoint function body, redirect to origin page with error message query param and form inputs as context so we can re-render page with original form inputs\n\n\nYes\n\n\nYes\n\n\nYes\n\n\nHigh\n\n\n\n\nValidate with Pydantic dependency, use session context to get form inputs from request, redirect to origin page from middleware with exception message and form inputs as context so we can re-render page with original form inputs\n\n\nYes\n\n\nYes\n\n\nYes\n\n\nHigh\n\n\n\n\nValidate in either Pydantic dependency or function endpoint body and directly return error message or error toast HTML partial in JSON, then mount error toast with HTMX or some simple layout-level Javascript\n\n\nYes\n\n\nYes\n\n\nNo\n\n\nLow\n\n\n\n\nPresently this template primarily uses option 1 but also supports option 2. Ultimately, I think option 5 will be preferable; support for that is planned for a future update or fork of this template."
  },
  {
    "objectID": "docs/installation.html",
    "href": "docs/installation.html",
    "title": "Installation",
    "section": "",
    "text": "If you use VSCode with Docker to develop in a container, the following VSCode Dev Container configuration will install all dependencies:\n{\n    \"name\": \"Python 3\",\n    \"image\": \"mcr.microsoft.com/devcontainers/python:1-3.12-bookworm\",\n    \"postCreateCommand\": \"sudo apt update && sudo apt install -y python3-dev libpq-dev graphviz && uv venv && uv sync\",\n    \"features\": {\n        \"ghcr.io/va-h/devcontainers-features/uv:1\": {\n            \"version\": \"latest\"\n        },\n        \"ghcr.io/devcontainers/features/docker-outside-of-docker:1\": {},\n        \"ghcr.io/rocker-org/devcontainer-features/quarto-cli:1\": {}\n    }\n}\nSimply create a .devcontainer folder in the root of the project and add a devcontainer.json file in the folder with the above content. VSCode may prompt you to install the Dev Container extension if you haven’t already, and/or to open the project in a container. If not, you can manually select “Dev Containers: Reopen in Container” from View &gt; Command Palette.\nIMPORTANT: If using this dev container configuration, you will need to set the DB_HOST environment variable to “host.docker.internal” in the .env file."
  },
  {
    "objectID": "docs/installation.html#install-all-dependencies-in-a-vscode-dev-container",
    "href": "docs/installation.html#install-all-dependencies-in-a-vscode-dev-container",
    "title": "Installation",
    "section": "",
    "text": "If you use VSCode with Docker to develop in a container, the following VSCode Dev Container configuration will install all dependencies:\n{\n    \"name\": \"Python 3\",\n    \"image\": \"mcr.microsoft.com/devcontainers/python:1-3.12-bookworm\",\n    \"postCreateCommand\": \"sudo apt update && sudo apt install -y python3-dev libpq-dev graphviz && uv venv && uv sync\",\n    \"features\": {\n        \"ghcr.io/va-h/devcontainers-features/uv:1\": {\n            \"version\": \"latest\"\n        },\n        \"ghcr.io/devcontainers/features/docker-outside-of-docker:1\": {},\n        \"ghcr.io/rocker-org/devcontainer-features/quarto-cli:1\": {}\n    }\n}\nSimply create a .devcontainer folder in the root of the project and add a devcontainer.json file in the folder with the above content. VSCode may prompt you to install the Dev Container extension if you haven’t already, and/or to open the project in a container. If not, you can manually select “Dev Containers: Reopen in Container” from View &gt; Command Palette.\nIMPORTANT: If using this dev container configuration, you will need to set the DB_HOST environment variable to “host.docker.internal” in the .env file."
  },
  {
    "objectID": "docs/installation.html#install-development-dependencies-manually",
    "href": "docs/installation.html#install-development-dependencies-manually",
    "title": "Installation",
    "section": "Install development dependencies manually",
    "text": "Install development dependencies manually\n\nuv\nMacOS and Linux:\nwget -qO- https://astral.sh/uv/install.sh | sh\nWindows:\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\nSee the uv installation docs for more information.\n\n\nPython\nInstall Python 3.12 or higher from either the official downloads page or using uv:\n# Installs the latest version\nuv python install\n\n\nDocker and Docker Compose\nInstall Docker Desktop and Docker Compose for your operating system by following the instructions in the documentation.\n\n\nPostgreSQL headers\nFor Ubuntu/Debian:\nsudo apt update && sudo apt install -y python3-dev libpq-dev\nFor macOS:\nbrew install postgresql\nFor Windows:\n\nNo installation required\n\n\n\nPython dependencies\nFrom the root directory, run:\nuv venv\nThis will create an in-project virtual environment. Then run:\nuv sync\nThis will install all dependencies.\n(Note: if psycopg2 installation fails, you probably just need to install the PostgreSQL headers first and then try again.)\n\n\nConfigure IDE\nIf you are using VSCode or Cursor as your IDE, you will need to select the uv-managed Python version as your interpreter for the project. Go to View &gt; Command Palette, search for Python: Select Interpreter, and select the Python version labeled ('.venv':venv).\nIt is also recommended to install the Python and Quarto IDE extensions."
  },
  {
    "objectID": "docs/installation.html#install-documentation-dependencies-manually",
    "href": "docs/installation.html#install-documentation-dependencies-manually",
    "title": "Installation",
    "section": "Install documentation dependencies manually",
    "text": "Install documentation dependencies manually\n\nQuarto CLI\nTo render the project documentation, you will need to download and install the Quarto CLI for your operating system.\n\n\nGraphviz\nArchitecture diagrams in the documentation are rendered with Graphviz.\nFor macOS:\nbrew install graphviz\nFor Ubuntu/Debian:\nsudo apt update && sudo apt install -y graphviz\nFor Windows:\n\nDownload and install from Graphviz.org"
  },
  {
    "objectID": "docs/installation.html#set-environment-variables",
    "href": "docs/installation.html#set-environment-variables",
    "title": "Installation",
    "section": "Set environment variables",
    "text": "Set environment variables\nCopy .env.example to .env with cp .env.example .env.\nGenerate a 256 bit secret key with openssl rand -base64 32 and paste it into the .env file.\nSet your desired database name, username, and password in the .env file.\nTo use password recovery, register a Resend account, verify a domain, get an API key, and paste the API key into the .env file.\nIf using the dev container configuration, you will need to set the DB_HOST environment variable to “host.docker.internal” in the .env file. Otherwise, set DB_HOST to “localhost” for local development. (In production, DB_HOST will be set to the hostname of the database server.)"
  },
  {
    "objectID": "docs/installation.html#start-development-database",
    "href": "docs/installation.html#start-development-database",
    "title": "Installation",
    "section": "Start development database",
    "text": "Start development database\nTo start the development database, run the following command in your terminal from the root directory:\ndocker compose up -d\nIf at any point you change the environment variables in the .env file, you will need to stop the database service and tear down the volume:\n# Don't forget the -v flag to tear down the volume!\ndocker compose down -v\nYou may also need to restart the terminal session to pick up the new environment variables. You can also add the --force-recreate and --build flags to the startup command to ensure the container is rebuilt:\ndocker compose up -d --force-recreate --build"
  },
  {
    "objectID": "docs/installation.html#run-the-development-server",
    "href": "docs/installation.html#run-the-development-server",
    "title": "Installation",
    "section": "Run the development server",
    "text": "Run the development server\nBefore running the development server, make sure the development database is running and tables and default permissions/roles are created first. Then run the following command in your terminal from the root directory:\nuvicorn main:app --host 0.0.0.0 --port 8000 --reload\nNavigate to http://localhost:8000/"
  },
  {
    "objectID": "docs/installation.html#lint-types-with-mypy",
    "href": "docs/installation.html#lint-types-with-mypy",
    "title": "Installation",
    "section": "Lint types with mypy",
    "text": "Lint types with mypy\nmypy ."
  },
  {
    "objectID": "docs/customization.html",
    "href": "docs/customization.html",
    "title": "Customization",
    "section": "",
    "text": "The project uses uv to manage dependencies:\n\nAdd new dependency: uv add &lt;dependency&gt;\nAdd development dependency: uv add --dev &lt;dependency&gt;\nRemove dependency: uv remove &lt;dependency&gt;\nUpdate lock file: uv lock\nInstall all dependencies: uv sync\nInstall only production dependencies: uv sync --no-dev\nUpgrade dependencies: uv lock --upgrade\n\n\n\n\nIf you are using VSCode or Cursor as your IDE, you will need to select the uv-managed Python version as your interpreter for the project. Go to View &gt; Command Palette, search for Python: Select Interpreter, and select the Python version labeled ('.venv':venv).\nIf your IDE does not automatically detect and display this option, you can manually select the interpreter by selecting “Enter interpreter path” and then navigating to the .venv/bin/python subfolder in your project directory.\n\n\n\nThe project uses Pytest for unit testing. It’s highly recommended to write and run tests before committing code to ensure nothing is broken!\nThe following fixtures, defined in tests/conftest.py, are available in the test suite:\n\nengine: Creates a new SQLModel engine for the test database.\nset_up_database: Sets up the test database before running the test suite by dropping all tables and recreating them to ensure a clean state.\nsession: Provides a session for database operations in tests.\nclean_db: Cleans up the database tables before each test by deleting all entries in the PasswordResetToken and User tables.\nauth_client: Provides a TestClient instance with access and refresh token cookies set, overriding the get_session dependency to use the session fixture.\nunauth_client: Provides a TestClient instance without authentication cookies set, overriding the get_session dependency to use the session fixture.\ntest_user: Creates a test user in the database with a predefined name, email, and hashed password.\n\nTo run the tests, use these commands:\n\nRun all tests: pytest\nRun tests in debug mode (includes logs and print statements in console output): pytest -s\nRun particular test files by name: pytest &lt;test_file_name&gt;\nRun particular tests by name: pytest -k &lt;test_name&gt;\n\n\n\n\nThe project uses type annotations and mypy for static type checking. To run mypy, use this command from the root directory:\nmypy .\nWe find that mypy is an enormous time-saver, catching many errors early and greatly reducing time spent debugging unit tests. However, note that mypy requires you type annotate every variable, function, and method in your code base, so taking advantage of it requires a lifestyle change!\n\n\n\nIn line with the llms.txt standard, we have provided a Markdown-formatted prompt—designed to help LLM agents understand how to work with this template—as a text file: llms.txt.\nOne use case for this file, if using the Cursor IDE, is to rename it to .cursorrules and place it in your project directory (see the Cursor docs on this for more information). Alternatively, you could use it as a custom system prompt in the web interface for ChatGPT, Claude, or the LLM of your choice.\nWe have also exposed the full Markdown-formatted project documentation as a single text file for easy downloading and embedding for RAG workflows."
  },
  {
    "objectID": "docs/customization.html#development-workflow",
    "href": "docs/customization.html#development-workflow",
    "title": "Customization",
    "section": "",
    "text": "The project uses uv to manage dependencies:\n\nAdd new dependency: uv add &lt;dependency&gt;\nAdd development dependency: uv add --dev &lt;dependency&gt;\nRemove dependency: uv remove &lt;dependency&gt;\nUpdate lock file: uv lock\nInstall all dependencies: uv sync\nInstall only production dependencies: uv sync --no-dev\nUpgrade dependencies: uv lock --upgrade\n\n\n\n\nIf you are using VSCode or Cursor as your IDE, you will need to select the uv-managed Python version as your interpreter for the project. Go to View &gt; Command Palette, search for Python: Select Interpreter, and select the Python version labeled ('.venv':venv).\nIf your IDE does not automatically detect and display this option, you can manually select the interpreter by selecting “Enter interpreter path” and then navigating to the .venv/bin/python subfolder in your project directory.\n\n\n\nThe project uses Pytest for unit testing. It’s highly recommended to write and run tests before committing code to ensure nothing is broken!\nThe following fixtures, defined in tests/conftest.py, are available in the test suite:\n\nengine: Creates a new SQLModel engine for the test database.\nset_up_database: Sets up the test database before running the test suite by dropping all tables and recreating them to ensure a clean state.\nsession: Provides a session for database operations in tests.\nclean_db: Cleans up the database tables before each test by deleting all entries in the PasswordResetToken and User tables.\nauth_client: Provides a TestClient instance with access and refresh token cookies set, overriding the get_session dependency to use the session fixture.\nunauth_client: Provides a TestClient instance without authentication cookies set, overriding the get_session dependency to use the session fixture.\ntest_user: Creates a test user in the database with a predefined name, email, and hashed password.\n\nTo run the tests, use these commands:\n\nRun all tests: pytest\nRun tests in debug mode (includes logs and print statements in console output): pytest -s\nRun particular test files by name: pytest &lt;test_file_name&gt;\nRun particular tests by name: pytest -k &lt;test_name&gt;\n\n\n\n\nThe project uses type annotations and mypy for static type checking. To run mypy, use this command from the root directory:\nmypy .\nWe find that mypy is an enormous time-saver, catching many errors early and greatly reducing time spent debugging unit tests. However, note that mypy requires you type annotate every variable, function, and method in your code base, so taking advantage of it requires a lifestyle change!\n\n\n\nIn line with the llms.txt standard, we have provided a Markdown-formatted prompt—designed to help LLM agents understand how to work with this template—as a text file: llms.txt.\nOne use case for this file, if using the Cursor IDE, is to rename it to .cursorrules and place it in your project directory (see the Cursor docs on this for more information). Alternatively, you could use it as a custom system prompt in the web interface for ChatGPT, Claude, or the LLM of your choice.\nWe have also exposed the full Markdown-formatted project documentation as a single text file for easy downloading and embedding for RAG workflows."
  },
  {
    "objectID": "docs/customization.html#project-structure",
    "href": "docs/customization.html#project-structure",
    "title": "Customization",
    "section": "Project structure",
    "text": "Project structure\n\nCustomizable folders and files\n\nFastAPI application entry point and GET routes: main.py\nFastAPI POST routes: routers/\n\nUser authentication endpoints: auth.py\nUser profile management endpoints: user.py\nOrganization management endpoints: organization.py\nRole management endpoints: role.py\n\nJinja2 templates: templates/\nStatic assets: static/\nUnit tests: tests/\nTest database configuration: docker-compose.yml\nHelper functions: utils/\n\nAuth helpers: auth.py\nDatabase helpers: db.py\nDatabase models: models.py\n\nEnvironment variables: .env\nCI/CD configuration: .github/\nProject configuration: pyproject.toml\nQuarto documentation:\n\nSource: index.qmd + docs/\nConfiguration: _quarto.yml\n\n\nMost everything else is auto-generated and should not be manually modified.\n\n\nDefining a web backend with FastAPI\nWe use FastAPI to define the “API endpoints” of our application. An API endpoint is simply a URL that accepts user requests and returns responses. When a user visits a page, their browser sends what’s called a “GET” request to an endpoint, and the server processes it (often querying a database), and returns a response (typically HTML). The browser renders the HTML, displaying the page.\nWe also create POST endpoints, which accept form submissions so the user can create, update, and delete data in the database. This template follows the Post-Redirect-Get (PRG) pattern to handle POST requests. When a form is submitted, the server processes the data and then returns a “redirect” response, which sends the user to a GET endpoint to re-render the page with the updated data. (See Architecture for more details.)\n\nRouting patterns in this template\nIn this template, GET routes are defined in the main entry point for the application, main.py. POST routes are organized into separate modules within the routers/ directory.\nWe name our GET routes using the convention read_&lt;name&gt;, where &lt;name&gt; is the name of the page, to indicate that they are read-only endpoints that do not modify the database.\nWe divide our GET routes into authenticated and unauthenticated routes, using commented section headers in our code that look like this:\n# --- Authenticated Routes ---\nSome of our routes take request parameters, which we pass as keyword arguments to the route handler. These parameters should be type annotated for validation purposes.\nSome parameters are shared across all authenticated or unauthenticated routes, so we define them in the common_authenticated_parameters and common_unauthenticated_parameters dependencies defined in main.py.\n\n\n\nHTML templating with Jinja2\nTo generate the HTML pages to be returned from our GET routes, we use Jinja2 templates. Jinja2’s hierarchical templates allow creating a base template (templates/base.html) that defines the overall layout of our web pages (e.g., where the header, body, and footer should go). Individual pages can then extend this base template. We can also template reusable components that can be injected into our layout or page templates.\nWith Jinja2, we can use the {% block %} tag to define content blocks, and the {% extends %} tag to extend a base template. We can also use the {% include %} tag to include a component in a parent template. See the Jinja2 documentation on template inheritance for more details.\n\nContext variables\nContext refers to Python variables passed to a template to populate the HTML. In a FastAPI GET route, we can pass context to a template using the templates.TemplateResponse method, which takes the request and any context data as arguments. For example:\n@app.get(\"/welcome\")\nasync def welcome(request: Request):\n    return templates.TemplateResponse(\n        \"welcome.html\",\n        {\"username\": \"Alice\"}\n    )\nIn this example, the welcome.html template will receive two pieces of context: the user’s request, which is always passed automatically by FastAPI, and a username variable, which we specify as “Alice”. We can then use the {{ username }} syntax in the welcome.html template (or any of its parent or child templates) to insert the value into the HTML.\n\n\nForm validation strategy\nWhile this template includes comprehensive server-side validation through Pydantic models and custom validators, it’s important to note that server-side validation should be treated as a fallback security measure. If users ever see the validation_error.html template, it indicates that our client-side validation has failed to catch invalid input before it reaches the server.\nBest practices dictate implementing thorough client-side validation via JavaScript and/or HTML input element pattern attributes to: - Provide immediate feedback to users - Reduce server load - Improve user experience by avoiding round-trips to the server - Prevent malformed data from ever reaching the backend\nServer-side validation remains essential as a security measure against malicious requests that bypass client-side validation, but it should rarely be encountered during normal user interaction. See templates/authentication/register.html for a client-side form validation example involving both JavaScript and HTML regex pattern matching.\n\n\nEmail templating\nPassword reset and other transactional emails are also handled through Jinja2 templates, located in the templates/emails directory. The email templates follow the same inheritance pattern as web templates, with base_email.html providing the common layout and styling.\nHere’s how the default password reset email template looks:\n\n\n\nDefault Password Reset Email Template\n\n\nThe email templates use inline CSS styles to ensure consistent rendering across email clients. Like web templates, they can receive context variables from the Python code (such as reset_url in the password reset template).\n\n\n\nWriting type annotated code\nPydantic is used for data validation and serialization. It ensures that the data received in requests meets the expected format and constraints. Pydantic models are used to define the structure of request and response data, making it easy to validate and parse JSON payloads.\nIf a user-submitted form contains data that has the wrong number, names, or types of fields, Pydantic will raise a RequestValidationError, which is caught by middleware and converted into an HTTP 422 error response.\nFor other, custom validation logic, we add Pydantic @field_validator methods to our Pydantic request models and then add the models as dependencies in the signatures of corresponding POST routes. FastAPI’s dependency injection system ensures that dependency logic is executed before the body of the route handler.\n\nDefining request models and custom validators\nFor example, in the UserRegister request model in routers/authentication.py, we add a custom validation method to ensure that the confirm_password field matches the password field. If not, it raises a custom PasswordMismatchError:\nclass PasswordMismatchError(HTTPException):\n    def __init__(self, field: str = \"confirm_password\"):\n        super().__init__(\n            status_code=422,\n            detail={\n                \"field\": field,\n                \"message\": \"The passwords you entered do not match\"\n            }\n        )\n\nclass UserRegister(BaseModel):\n    name: str\n    email: EmailStr\n    password: str\n    confirm_password: str\n\n    # Custom validators are added as class attributes\n    @field_validator(\"confirm_password\", check_fields=False)\n    def validate_passwords_match(cls, v: str, values: dict[str, Any]) -&gt; str:\n        if v != values[\"password\"]:\n            raise PasswordMismatchError()\n        return v\n    # ...\nWe then add this request model as a dependency in the signature of our POST route:\n@app.post(\"/register\")\nasync def register(request: UserRegister = Depends()):\n    # ...\nWhen the user submits the form, Pydantic will first check that all expected fields are present and match the expected types. If not, it raises a RequestValidationError. Then, it runs our custom field_validator, validate_passwords_match. If it finds that the confirm_password field does not match the password field, it raises a PasswordMismatchError. These exceptions can then be caught and handled by our middleware.\n(Note that these examples are simplified versions of the actual code.)\n\n\nConverting form data to request models\nIn addition to custom validation logic, we also need to define a method on our request models that converts form data into the request model. Here’s what that looks like in the UserRegister request model from the previous example:\nclass UserRegister(BaseModel):\n    # ...\n\n    @classmethod\n    async def as_form(\n        cls,\n        name: str = Form(...),\n        email: EmailStr = Form(...),\n        password: str = Form(...),\n        confirm_password: str = Form(...)\n    ):\n        return cls(\n            name=name,\n            email=email,\n            password=password,\n            confirm_password=confirm_password\n        )\n\n\nMiddleware exception handling\nMiddlewares—which process requests before they reach the route handlers and responses before they are sent back to the client—are defined in main.py. They are commonly used in web development for tasks such as error handling, authentication token validation, logging, and modifying request/response objects.\nThis template uses middlewares exclusively for global exception handling; they only affect requests that raise an exception. This allows for consistent error responses and centralized error logging. Middleware can catch exceptions raised during request processing and return appropriate HTTP responses.\nMiddleware functions are decorated with @app.exception_handler(ExceptionType) and are executed in the order they are defined in main.py, from most to least specific.\nHere’s a middleware for handling the PasswordMismatchError exception from the previous example, which renders the errors/validation_error.html template with the error details:\n@app.exception_handler(PasswordMismatchError)\nasync def password_mismatch_exception_handler(request: Request, exc: PasswordMismatchError):\n    return templates.TemplateResponse(\n        request,\n        \"errors/validation_error.html\",\n        {\n            \"status_code\": 422,\n            \"errors\": {\"error\": exc.detail}\n        },\n        status_code=422,\n    )\n\n\n\nDatabase configuration and access with SQLModel\nSQLModel is an Object-Relational Mapping (ORM) library that allows us to interact with our PostgreSQL database using Python classes instead of writing raw SQL. It combines the features of SQLAlchemy (a powerful database toolkit) with Pydantic’s data validation.\n\nModels and relationships\nOur database models are defined in utils/models.py. Each model is a Python class that inherits from SQLModel and represents a database table. The key models are:\n\nOrganization: Represents a company or team\nUser: Represents a user account with name, email, and avatar\nRole: Represents a set of permissions within an organization\nPermission: Represents specific actions a user can perform (defined by ValidPermissions enum)\nPasswordResetToken: Manages password reset functionality with expiration\nUserPassword: Stores hashed user passwords separately from user data\n\nTwo additional models are used by SQLModel to manage many-to-many relationships; you generally will not need to interact with them directly:\n\nUserRoleLink: Maps users to their roles (many-to-many relationship)\nRolePermissionLink: Maps roles to their permissions (many-to-many relationship)\n\nHere’s an entity-relationship diagram (ERD) of the current database schema, automatically generated from our SQLModel definitions:\n\n\n\nDatabase Schema\n\n\n\n\nDatabase helpers\nDatabase operations are facilitated by helper functions in utils/db.py. Key functions include:\n\nset_up_db(): Initializes the database schema and default data (which we do on every application start in main.py)\nget_connection_url(): Creates a database connection URL from environment variables in .env\nget_session(): Provides a database session for performing operations\n\nTo perform database operations in route handlers, inject the database session as a dependency:\n@app.get(\"/users\")\nasync def get_users(session: Session = Depends(get_session)):\n    users = session.exec(select(User)).all()\n    return users\nThe session automatically handles transaction management, ensuring that database operations are atomic and consistent.\nThere is also a helper method on the User model that checks if a user has a specific permission for a given organization. Its first argument must be a ValidPermissions enum value (from utils/models.py), and its second argument must be an Organization object or an int representing an organization ID:\npermission = ValidPermissions.CREATE_ROLE\norganization = session.exec(select(Organization).where(Organization.name == \"Acme Inc.\")).first()\n\nuser.has_permission(permission, organization)\nYou should create custom ValidPermissions enum values for your application and validate that users have the necessary permissions before allowing them to modify organization data resources.\n\n\nCascade deletes\nCascade deletes (in which deleting a record from one table deletes related records from another table) can be handled at either the ORM level or the database level. This template handles cascade deletes at the ORM level, via SQLModel relationships. Inside a SQLModel Relationship, we set:\nsa_relationship_kwargs={\n    \"cascade\": \"all, delete-orphan\"\n}\nThis tells SQLAlchemy to cascade all operations (e.g., SELECT, INSERT, UPDATE, DELETE) to the related table. Since this happens through the ORM, we need to be careful to do all our database operations through the ORM using supported syntax. That generally means loading database records into Python objects and then deleting those objects rather than deleting records in the database directly.\nFor example,\nsession.exec(delete(Role))\nwill not trigger the cascade delete. Instead, we need to select the role objects and then delete them:\nfor role in session.exec(select(Role)).all():\n    session.delete(role)\nThis is slower than deleting the records directly, but it makes many-to-many relationships much easier to manage."
  },
  {
    "objectID": "docs/contributing.html",
    "href": "docs/contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "When opening a new issue or submitting a bug report, please include:\n\nA clear, descriptive title\nFor bug reports:\n\nDescription of the expected behavior\nDescription of the actual behavior\nSteps to reproduce the issue\nVersion information (OS, Python version, package version)\nAny relevant error messages or screenshots\n\nFor feature requests:\n\nDescription of the proposed feature\nUse case or motivation for the feature\nAny implementation suggestions (optional)\n\n\nLabels help categorize issues: - Use bug for reporting problems - Use enhancement for feature requests - Use documentation for documentation improvements - Use question for general queries\n\n\n\nTo contribute code to the project:\n\nFork the repository and clone your fork locally\nCreate a new branch from main with a descriptive name\nReview the customization, architecture, and authentication pages for guidance on design patterns and code structure and style\nEnsure all tests pass, including mypy type checking\nStage, commit, and push your changes to the branch:\n\nUse clear, descriptive commit messages\nKeep commits focused and atomic\n\nSubmit your pull request:\n\nProvide a clear description of the changes\nLink to any related issues\n\n\n\n\n\nThe README and documentation website are rendered with Quarto. If you ,make changes to the .qmd files in the root folder and the docs folder, run the following commands to re-render the docs:\n# To render the documentation website\nquarto render\n# To render the README\nquarto render index.qmd --output-dir . --output README.md --to gfm\nDue to a quirk of Quarto, an unnecessary index.html file is created in the root folder when the README is rendered. This file can be safely deleted.\nNote that even if your pull request is merged, your changes will not be reflected on the live website until a maintainer republishes the docs."
  },
  {
    "objectID": "docs/contributing.html#contributors",
    "href": "docs/contributing.html#contributors",
    "title": "Contributing",
    "section": "",
    "text": "When opening a new issue or submitting a bug report, please include:\n\nA clear, descriptive title\nFor bug reports:\n\nDescription of the expected behavior\nDescription of the actual behavior\nSteps to reproduce the issue\nVersion information (OS, Python version, package version)\nAny relevant error messages or screenshots\n\nFor feature requests:\n\nDescription of the proposed feature\nUse case or motivation for the feature\nAny implementation suggestions (optional)\n\n\nLabels help categorize issues: - Use bug for reporting problems - Use enhancement for feature requests - Use documentation for documentation improvements - Use question for general queries\n\n\n\nTo contribute code to the project:\n\nFork the repository and clone your fork locally\nCreate a new branch from main with a descriptive name\nReview the customization, architecture, and authentication pages for guidance on design patterns and code structure and style\nEnsure all tests pass, including mypy type checking\nStage, commit, and push your changes to the branch:\n\nUse clear, descriptive commit messages\nKeep commits focused and atomic\n\nSubmit your pull request:\n\nProvide a clear description of the changes\nLink to any related issues\n\n\n\n\n\nThe README and documentation website are rendered with Quarto. If you ,make changes to the .qmd files in the root folder and the docs folder, run the following commands to re-render the docs:\n# To render the documentation website\nquarto render\n# To render the README\nquarto render index.qmd --output-dir . --output README.md --to gfm\nDue to a quirk of Quarto, an unnecessary index.html file is created in the root folder when the README is rendered. This file can be safely deleted.\nNote that even if your pull request is merged, your changes will not be reflected on the live website until a maintainer republishes the docs."
  },
  {
    "objectID": "docs/contributing.html#maintainers",
    "href": "docs/contributing.html#maintainers",
    "title": "Contributing",
    "section": "Maintainers",
    "text": "Maintainers\n\nGit flow\nWhen creating new features,\n\nOpen a Github issue with the label feature and assign it to yourself.\nCreate a new branch from the issue sidebar.\nFollow the instructions in the popup to check out the branch locally and make your changes on the branch.\nCommit your changes and push to the branch.\nWhen you are ready to merge, open a pull request from the branch to main.\nAssign someone else for code review.\n\n\n\nPublishing the documentation\nTo publish the documentation to GitHub Pages, run the following command:\nquarto publish gh-pages"
  }
]